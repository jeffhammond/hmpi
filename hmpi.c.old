#define _GNU_SOURCE

#ifdef MPI
#define MPI_FOO
#undef MPI
#endif
#include "hmpi.h"
#ifdef MPI_FOO
#define MPI
#else
#undef MPI
#endif


#include "profile.h"
#include <sched.h>
#include <malloc.h>
#include <stdlib.h>
#include <stdio.h>
#include <string.h>

#define likely(x)       __builtin_expect((x),1)
#define unlikely(x)     __builtin_expect((x),0)


#ifdef _PROFILE
struct profile_info_t* g_profile_info;
__thread unsigned long long g_timerfreq = 0;
//double g_hrttimer_startvalue = 0;
//int prof_array[1024] = {0};
volatile int g_calibrate_counter = 0;
#endif





int g_nthreads=-1;
int g_rank=-1;
static int g_size=-1;

HMPI_Comm HMPI_COMM_WORLD;

//static std::vector<pthread_t> g_threads;
//static std::vector<MPI_Comm> g_tcomms;
static MPI_Comm* g_tcomms;

static __thread int g_tl_tid=-1;

static void (*g_entry)();

//Each thread has a list of send and receive requests.
//The receive requests are managed only by the owning thread.
//The send requests list for a particular thread contains sends whose target is
// that thread.  Other threads place their send requests on this list, and the
// thread owning the list matches receives against them.

//static std::vector<std::list<HMPI_Request*> > g_recv_reqs;
static __thread HMPI_Request* g_recv_reqs = NULL;

static HMPI_Request** g_send_reqs = NULL;
static pthread_mutex_t* g_send_muts = NULL;

#if 0
static inline void asdf_memcpy(void* restrict b, const void* restrict a, size_t n) {
        char *s1 = (char*)b;
        const char *s2 = (const char*)a;
        for(; 0<n; --n) *s1++ = *s2++;
}
#endif

static inline void add_recv_req(HMPI_Request *req) {
  req->next = g_recv_reqs;
  req->prev = NULL;
  if(req->next != NULL) {
    req->next->prev = req;
  }

  g_recv_reqs = req;
}


static inline void add_send_req(HMPI_Request *req, int tid) {
  pthread_mutex_lock(&g_send_muts[tid]);
  req->next = g_send_reqs[tid];
  req->prev = NULL;

  if(req->next != NULL) {
    req->next->prev = req;
  }

  g_send_reqs[tid] = req;
  pthread_mutex_unlock(&g_send_muts[tid]);
}


static inline void remove_recv_req(HMPI_Request *req) {
  if(req->prev == NULL) {
      //Head of list
      g_recv_reqs = req->next;
  } else {
      req->prev->next = req->next;
  }

  if(req->next != NULL) {
      req->next->prev = req->prev;
  }

}


static inline void remove_send_req(HMPI_Request *req) {
  pthread_mutex_lock(&g_send_muts[g_tl_tid]);
  if(req->prev == NULL) {
      //Head of list
      g_send_reqs[g_tl_tid] = req->next;
  } else {
      req->prev->next = req->next;
  }

  if(req->next != NULL) {
      req->next->prev = req->prev;
  }

  pthread_mutex_unlock(&g_send_muts[g_tl_tid]);
}


static inline int match_recv(HMPI_Request* recv_req, HMPI_Request** send_req) {
    //Iterate over g_send_reqs[g_tl_tid]
    HMPI_Request* cur;

    pthread_mutex_lock(&g_send_muts[g_tl_tid]);
    for(cur = g_send_reqs[g_tl_tid]; cur != NULL; cur = cur->next) {
        //The send request can't have ANY_SOURCE or ANY_TAG
        if(cur->proc == recv_req->proc ||
                recv_req->proc == MPI_ANY_SOURCE) {
            if(cur->tag == recv_req->tag || recv_req->tag == MPI_ANY_TAG) {
                //Remove send req from list and return
                *send_req = cur;

                if(cur->prev == NULL) {
                    //Head of list
                    g_send_reqs[g_tl_tid] = cur->next;
                } else {
                    cur->prev->next = cur->next;
                }

                if(cur->next != NULL) {
                    cur->next->prev = cur->prev;
                }
                
                pthread_mutex_unlock(&g_send_muts[g_tl_tid]);
                return 1;
            }
        }
    }

    pthread_mutex_unlock(&g_send_muts[g_tl_tid]);
    return 0;
}


static inline void update_reqstat(HMPI_Request *req, int stat) {
  //pthread_mutex_lock(&req->statlock);
  req->stat = stat;
  //OPA_swap_int(&req->stat, stat);
  //pthread_mutex_unlock(&req->statlock);
}


static inline int get_reqstat(HMPI_Request *req) {
  int stat;
  //pthread_mutex_lock(&req->statlock);
  stat = req->stat;
  //return OPA_load_int(&req->stat);
  //pthread_mutex_unlock(&req->statlock);
  return stat;
}


int barrier(barrier_t *barrier);
int barrier_test(barrier_t *barrier);
int barrier_wait(barrier_t *barrier);


// this is called by pthread create and then calls the real function!
void* trampoline(void* tid) {
  // save thread-id in thread-local storage
  g_tl_tid = (int)(unsigned long)tid;

//  printf("%d:%d entered trampoline\n", g_rank, g_tl_tid); fflush(stdout);
#ifdef _PROFILE
//    HRT_INIT(0, g_timerfreq);
#endif

  // barrier to avoid race in tid ...
  barrier(&HMPI_COMM_WORLD->barr);
  //while(!barrier_test(&HMPI_COMM_WORLD->barr));
  barrier_wait(&HMPI_COMM_WORLD->barr);

//  printf("%d:%d g_entry now\n", g_rank, g_tl_tid); fflush(stdout);
  // call user function
  g_entry();

  //PROFILE_SHOW_REDUCE(g_profile_info[g_tl_tid], barrier, g_nthreads*g_rank+g_tl_tid);
  PROFILE_SHOW_REDUCE(g_profile_info[g_tl_tid], alltoall, g_nthreads*g_rank+g_tl_tid);
  return NULL;
}


#ifdef ANDY_BARRIER
static inline int mylog2(int v) {
    int l = 0;

    while(v >>= 1) l++;
    return l;
}

int barrier_init(barrier_t *barrier,int needed) {
#if 0
  barrier->local_sense = (int*)calloc(sizeof(int), g_nthreads);
  barrier->count = g_nthreads;
  barrier->global_sense = 0;
#endif
  int i;

  //Compute log2 of nthreads
  //barrier->log = ceil(log2(g_nthreads));
  barrier->log = mylog2(g_nthreads);

  barrier->flags[0] = (int*)calloc(sizeof(int), barrier->log * g_nthreads);
  barrier->flags[1] = (int*)calloc(sizeof(int), barrier->log * g_nthreads);

  //barrier->partnerflags[0] = calloc(sizeof(int), g_nthreads);
  //barrier->partnerflags[1] = calloc(sizeof(int), g_nthreads);

  barrier->parity = (int*)calloc(sizeof(int), g_nthreads);
  barrier->sense = (int*)calloc(sizeof(int), g_nthreads);

  for(i = 0; i < g_nthreads; i++) {
      barrier->sense[i] = ~0;
  }

  //barrier->allnodes = calloc(sizeof(int), g_nthreads);
  return 0;
}

int barrier_destroy(barrier_t *barrier) {
  //free(barrier->local_sense);
  return 0;
}

//Enter barrier
static inline int barrier(barrier_t *barrier) {
#if 0
//  printf("%d enter barrier\n", g_tl_tid); fflush(stdout);
  int local_sense = barrier->local_sense[g_tl_tid] = ~barrier->local_sense[g_tl_tid];

  //if(__sync_fetch_and_sub(&barrier->count, (int)1) == 1) {
  int val = __sync_fetch_and_sub(&barrier->count, (int)1);
  if(val == 1) {
      barrier->count = g_nthreads;
      barrier->global_sense = local_sense;
//      printf("%d toggle barrier\n", g_tl_tid); fflush(stdout);
      return 1;
  }

//  printf("%d barrier val %d\n", g_tl_tid, val); fflush(stdout);
#endif
  return 0;
}

//Test barrier completion
static inline int barrier_test(barrier_t *barrier) {
    //return barrier->global_sense == barrier->local_sense[g_tl_tid];
    return 0;
}

static inline int barrier_wait(barrier_t *barrier) {
  int instance;
  int parity = barrier->parity[g_tl_tid];
  int sense = barrier->parity[g_tl_tid];

  //printf("%d barrier wait\n", g_tl_tid); fflush(stdout);

  for(instance = 0; instance < barrier->log; instance++) {
    //Set flag i on thread g_tl_tid + 1 << instance % g_nthreads  
    int thr = (g_tl_tid + (1 << instance)) % g_nthreads;
    barrier->flags[parity][thr * barrier->log + instance] = sense;
    while(barrier->flags[parity][g_tl_tid * barrier->log + instance] != sense);
  }

  barrier->parity[g_tl_tid] = 1 - parity;
  barrier->sense[g_tl_tid] = ~sense;

  //printf("%d barrier finished\n", g_tl_tid); fflush(stdout);
#if 0
  while(!barrier_test(barrier));
  //    printf("%d finish barrier\n", g_tl_tid); fflush(stdout);
#endif

  return 0;
}

#endif

#ifdef COUNTER_BARRIER
int barrier_init(barrier_t *barrier,int needed) {
  barrier->counter=(int*)calloc(1,needed*sizeof(int));
  //barrier->expected=(int*)calloc(1,needed*sizeof(int));
  //barrier->counter=(cache_line_t*)calloc(sizeof(cache_line_t),needed);
  //barrier->expected=(cache_line_t*)calloc(sizeof(cache_line_t),needed);
  pthread_mutex_init(&barrier->lock, NULL);
  return 0;
}

int barrier_destroy(barrier_t *barrier) {
  free(barrier->counter);
  free(barrier->expected);
  return 0;
}

int barrier(barrier_t *barrier) {
  pthread_mutex_lock(&barrier->lock);
  //barrier->counter[g_tl_tid].val++;
  barrier->counter[g_tl_tid]++;
  pthread_mutex_unlock(&barrier->lock);

  //barrier->expected[g_tl_tid]++;
  return 0;
}

int barrier_test(barrier_t *barrier) {
  int done=1;
  int i;

  //TODO - set it up so that only one thread iterates over all the thread variables.
  // That thread waits for all to increment, then increments its own.
  // all other threads just watch for the signal from the lead thread.

  //Another trick to try is to put each individual counter on its own cache line.
  //Make a struct with the counter then a pad to a cache line and do the same barrier/.
  pthread_mutex_lock(&barrier->lock);
  for(i=0; i<g_nthreads; i++) {
    //if(barrier->expected[g_tl_tid] > barrier->counter[i]) {
    //if(barrier->counter[g_tl_tid].val > barrier->counter[i].val) {
    if(barrier->counter[g_tl_tid] > barrier->counter[i]) {
        done=0;
        break;
    }
  }
  pthread_mutex_unlock(&barrier->lock);
  return done;
}

static inline void HMPI_Progress();
int barrier_wait(barrier_t *barrier) {
  while(!barrier_test(barrier)) /*{HMPI_Progress();}*/;
  return 0;
}
#endif
#ifdef PTHREAD_BARRIER
int barrier_init(barrier_t *barrier,int needed) {
  pthread_barrier_init(barrier, NULL, needed);
}
int barrier_destroy(barrier_t *barrier) {
  pthread_barrier_destroy(barrier);
}
int barrier(barrier_t *barrier) {
  pthread_barrier_wait(barrier);
}
int barrier_test(barrier_t *barrier) {
  //printf("barrier_test doesn't work in pthread ...\n");
  return 1;
}
int barrier_wait(barrier_t *barrier) {}
#endif


int HMPI_Init(int *argc, char ***argv, int nthreads, void (*start_routine)())
{
  pthread_t* threads;
  int provided;
  long int thr;

  g_entry = start_routine;
  g_nthreads = nthreads;

//  printf("before MPI_Init\n"); fflush(stdout);
  MPI_Init_thread(argc, argv, MPI_THREAD_MULTIPLE, &provided);
  assert(MPI_THREAD_MULTIPLE == provided);
#ifdef DEBUG
  printf("after MPI_Init\n"); fflush(stdout);
#endif
  
  HMPI_COMM_WORLD = (HMPI_Comm_info*)malloc(sizeof(HMPI_Comm_info));
  HMPI_COMM_WORLD->mpicomm = MPI_COMM_WORLD;
  barrier_init(&HMPI_COMM_WORLD->barr, nthreads);

  //HMPI_COMM_WORLD->sinfo = (HMPI_Data_info*)malloc(sizeof(HMPI_Data_info) * nthreads);
  //HMPI_COMM_WORLD->rinfo = (HMPI_Data_info*)malloc(sizeof(HMPI_Data_info) * nthreads);
  HMPI_COMM_WORLD->sbuf = (volatile void**)malloc(sizeof(void*) * nthreads);
  HMPI_COMM_WORLD->rbuf = (volatile void**)malloc(sizeof(void*) * nthreads);
  HMPI_COMM_WORLD->scount = (volatile int*)malloc(sizeof(int) * nthreads);
  HMPI_COMM_WORLD->rcount = (volatile int*)malloc(sizeof(int) * nthreads);
  HMPI_COMM_WORLD->stype = (volatile MPI_Datatype*)malloc(sizeof(MPI_Datatype) * nthreads);
  HMPI_COMM_WORLD->rtype = (volatile MPI_Datatype*)malloc(sizeof(MPI_Datatype) * nthreads);

  //g_threads.resize(nthreads);
  threads = (pthread_t*)malloc(sizeof(pthread_t) * nthreads);

  //g_allrequests.resize(nthreads);
  //g_recv_reqs.resize(nthreads);
  //g_send_reqs.resize(nthreads);
  //g_send_muts.resize(nthreads);
  g_send_reqs = (HMPI_Request**)malloc(sizeof(HMPI_Request*) * nthreads);
  g_send_muts = (pthread_mutex_t*)malloc(sizeof(pthread_mutex_t) * nthreads);

  //g_tcomms.resize(nthreads);
  g_tcomms = (MPI_Comm*)malloc(sizeof(MPI_Comm) * nthreads);

#ifdef _PROFILE
    g_profile_info = (profile_info_t*)calloc(sizeof(struct profile_info_t), nthreads);
#endif

  MPI_Comm_rank(MPI_COMM_WORLD, &g_rank);
  MPI_Comm_size(MPI_COMM_WORLD, &g_size);

 
  //Do per-thread initialization that must be complete for all threads before
  // actually starting the threads. 
  for(thr=0; thr < nthreads; thr++) {
    // create one world communicator for each thread 
    MPI_Comm_dup(MPI_COMM_WORLD, &g_tcomms[thr]);

    // Initialize send requests list and lock
    g_send_reqs[thr] = NULL;
    pthread_mutex_init(&g_send_muts[thr], NULL);
  }

  // spawn threads locally
  pthread_attr_t attr;
  for(thr=0; thr < nthreads; thr++) {
    //Create the thread
    pthread_attr_init(&attr);
    int rc = pthread_create(&threads[thr], &attr, trampoline, (void *)thr);

    //Set affinity -- pin each thread to one core
    cpu_set_t cpuset;
    CPU_ZERO(&cpuset);
    CPU_SET(thr, &cpuset);

    rc = pthread_setaffinity_np(threads[thr], sizeof(cpu_set_t), &cpuset);
    if(rc) {
      printf("%d:%ld pthread_setaffinity_np error %s\n", g_rank, thr, strerror(rc));
      MPI_Abort(MPI_COMM_WORLD, 0);
    }
  }


  for(thr=0; thr<nthreads; thr++) {
    pthread_join(threads[thr], NULL);
  }

  free(g_send_reqs);
  free(g_send_muts);
  free(threads);
  free(g_tcomms);
  return 0;
}


int HMPI_Abort( HMPI_Comm comm, int errorcode ) {
  printf("HMPI: user code called MPI_Abort!\n");
  return MPI_Abort(comm->mpicomm, errorcode);
}


int HMPI_Comm_rank(HMPI_Comm comm, int *rank) {
  
  //printf("[%i] HMPI_Comm_rank()\n", g_rank*g_nthreads+g_tl_tid);
  if(comm->mpicomm != MPI_COMM_WORLD) {
    printf("only MPI_COMM_WORLD is supported so far\n");
    MPI_Abort(comm->mpicomm, 0);
  }
    
  *rank = g_nthreads*g_rank+g_tl_tid;
  return 0;
}

int HMPI_Comm_size ( HMPI_Comm comm, int *size ) {
  
  if(comm->mpicomm != MPI_COMM_WORLD) {
    printf("only MPI_COMM_WORLD is supported so far\n");
    MPI_Abort(comm->mpicomm, 0);
  }
    
  *size = g_size*g_nthreads;
  return 0;
}


// AWF new function - barrier only among local threads
void HMPI_Barrier_local(HMPI_Comm comm)
{
  barrier(&comm->barr);
  barrier_wait(&comm->barr);
}


int HMPI_Finalize() {

  HMPI_Barrier(HMPI_COMM_WORLD);

  int r;
  HMPI_Comm_rank(HMPI_COMM_WORLD, &r);
  //PROFILE_SHOW_REDUCE(match, g_rank);

  if(g_tl_tid == 0) {

    MPI_Finalize();
  }

  return 0;
}


// global progress function
static inline int HMPI_Progress_request(HMPI_Request *req);
static inline int HMPI_Progress_recv(HMPI_Request *recv_req);


//We assume req->type == HMPI_SEND and req->stat == 0 (uncompleted send)
static inline int HMPI_Progress_send(HMPI_Request *req) {

    //Poll local receives in the recv reqs list.
    // We do this to prevent deadlock when local threads are exchange messages
    // with each other.  Normally no work is done on a send request, but if
    // the app blocks waiting for it to complete, a neighbor thread could also
    // block on its send and neither of their receives are ever completed.

#if 0
    for(std::list<HMPI_Request*>::iterator iter=g_recv_reqs[g_tl_tid].begin();
          iter != g_recv_reqs[g_tl_tid].end(); ++iter) {
        HMPI_Progress_recv(*iter);
    }
#endif
    //TODO - this visits most rescent receives first.  maybe iterate backwards
    // to progress oldest receives first?
    HMPI_Request* cur;

    for(cur = g_recv_reqs; cur != NULL; cur = cur->next) {
        HMPI_Progress_recv(cur);
    }

    return get_reqstat(req);
}


static inline int HMPI_Progress_recv(HMPI_Request *recv_req) {
    //Try to match from the local send reqs list
    HMPI_Request* send_req;

    if(match_recv(recv_req, &send_req)) {
#ifdef DEBUG
      printf("[%i] [recv] found send from %i (%x) for buf %x in uq (tag: %i, size: %i, status: %x)\n",
              g_rank*g_nthreads+g_tl_tid, send_req->proc, send_req->buf, recv_req->buf, send_req->tag, send_req->size, get_reqstat(send_req));
#endif

      int sendsize = send_req->size;
      if(unlikely(sendsize != recv_req->size)) {
        //printf("[recv] message of size %i truncated to %i (doesn't fit in matching receive buffer)!\n", sendsize, recv_req->size);
        sendsize = recv_req->size;
      }

      // copy message to destination
      //printf("[%i] memcpy %p -> %p (%i)\n",
      //        g_rank*g_nthreads+g_tl_tid, send_req->buf, recv_req->buf, sendsize);
      //fflush(stdout);

      memcpy(recv_req->buf, send_req->buf, sendsize);

      //Mark send and receive requests done
      update_reqstat(send_req, 1);
      update_reqstat(recv_req, 1);

      //Remove the recv from the request list
      remove_recv_req(recv_req);
      return 1;
    }

    return 0;
}


static inline int HMPI_Progress_request(HMPI_Request *req) {
  //printf("%d progress type %d\n", g_rank*g_nthreads+g_tl_tid, req->type);
  //fflush(stdout);

  if(req->type == HMPI_SEND) {
      return HMPI_Progress_send(req);
  } else if(req->type == HMPI_RECV) {
      return HMPI_Progress_recv(req);
#if 0
    //TODO - Try to match from the local send reqs list


    // check if in UQ (needs to be done because the checks are not atomic)
    ruqelem_t *ret;

    //if(match(req, &uq[g_tl_tid], &ret)) {
    if(match(req, g_tl_tid, &ret)) {
#ifdef DEBUG
      printf("[%i] [recv] found send from %i (%x) for buf %x in uq (tag: %i, size: %i, status: %x)\n",
              g_rank*g_nthreads+g_tl_tid, ret->proc, ret->buf, req->buf, ret->tag, ret->size, get_reqstat(ret));
#endif

      int sendsize = ret->size;
      if(sendsize != req->size) {
        printf("[recv] message of size %i truncated to %i (doesn't fit in matching receive buffer)! %d\n", sendsize, req->size, uq[g_tl_tid].size());
        sendsize = req->size;
      }
      // copy message to destination
      //printf("[%i] memcpy %x -> %x (%i)\n",
      //        g_rank*g_nthreads+g_tl_tid, ret->buf, req->buf, sendsize);
      memcpy(req->buf, ret->buf, sendsize);
      //for(int k=0; k<sendsize; ++k) *((char*)req->buf+k)=*((char*)ret->buf+k);

      // mark send as done too
      update_reqstat(ret, 1);
      // mark request as done
      update_reqstat(req, 1);

      return 1;
    }
#endif
  } // HMPI_RECV
  else if(req->type == MPI_SEND || req->type == MPI_RECV) {
    int flag;


    //printf("%d testi req %d\n", g_rank*g_nthreads+g_tl_tid, req->type);
    MPI_Test(&req->req, &flag, req->status);

    update_reqstat(req, flag);
//    if(flag && req->type == MPI_RECV) {
//        remove_recv_req(req);
//    }
    return flag;
  }

  else if(req->type == HMPI_RECV_ANY_SOURCE) {
    if(HMPI_Progress_recv(req)) {
        return 1;
    }

#if 0
    // check if we received something from local thread
    ruqelem_t *ret;
    //if(match(req, &uq[g_tl_tid], &ret)) {
    if(match(req, g_tl_tid, &ret)) {
#ifdef DEBUG
      printf("[%i] [recv] found send from %i into %x in uq (tag: %i, size: %i, status: %x)\n", g_rank*g_nthreads+g_tl_tid, ret->proc, ret->buf, ret->tag, ret->size, get_reqstat(ret));
#endif
      int sendsize = ret->size;
      if(sendsize > req->size) {
        printf("[recv] message of size %i truncated to %i(doesn't fit in matching receive buffer)!\n", sendsize, req->size);
        sendsize = req->size;
      }

      // copy message to destination
      memcpy(req->buf, ret->buf, sendsize);

      // mark send as done too
      update_reqstat(ret, 1);
      // mark request as done
      update_reqstat(req, 1);

      return 1;
    } 
#endif

    // check if we can get something via the MPI library
    int flag=0;
    MPI_Iprobe(MPI_ANY_SOURCE, req->tag, req->comm, &flag, req->status);
    if(flag) {
      MPI_Recv(req->buf, req->size, req->datatype, req->status->MPI_SOURCE, req->tag, req->comm, req->status);
      remove_recv_req(req);
      return 1;
    }
  } //HMPI_RECV_ANY_SOURCE
  return 0;
}


static inline void HMPI_Progress() {
#if 0
    for(std::list<HMPI_Request*>::iterator iter=g_recv_reqs[g_tl_tid].begin();
          iter != g_recv_reqs[g_tl_tid].end(); ++iter) {
        HMPI_Progress_request(*iter);
    }
#endif
    //TODO - this visits most rescent receives first.  maybe iterate backwards
    // to progress oldest receives first?
    HMPI_Request* cur;
    for(cur = g_recv_reqs; cur != NULL; cur = cur->next) {
        HMPI_Progress_recv(cur);
    }

#if 0
  //if(g_allrequests[g_tl_tid].empty()) {
  //    return;
  //}

  //printf("progress req list size %d\n", g_allrequests[g_tl_tid].size());
  //fflush(stdout);
  for(std::list<HMPI_Request*>::iterator iter=g_allrequests[g_tl_tid].begin();
          iter != g_allrequests[g_tl_tid].end(); ++iter) {
    if(get_reqstat(*iter) != 1) {
        HMPI_Progress_request(*iter);
    }
#if 0
    if(HMPI_Progress_request(*iter)) {
        std::list<HMPI_Request*>::iterator old = iter;
        ++iter;
        g_allrequests[g_tl_tid].erase(old);
    } else {
        ++iter;
    }
#endif
  }
#endif
}

int HMPI_Test(HMPI_Request *req, int *flag, MPI_Status *status)
{
  if(get_reqstat(req) == 0) {
      req->status = status;
      *flag = HMPI_Progress_request(req);
  } else {
    *flag = 1;
  }
  return MPI_SUCCESS;

#if 0
  //HMPI_Progress();
  if(get_reqstat(req) != 1) HMPI_Progress_request(req);

  if(get_reqstat(req) == 1) {
    //printf("req complete\n");
    update_reqstat(req, 0);
    remove_req(req);
    if(status!=MPI_STATUS_IGNORE) *status=req->status;
    *flag=1; 
  } else {
    *flag=0;
  }

  return MPI_SUCCESS;
#endif
}


int HMPI_Wait(HMPI_Request *request, MPI_Status *status) {
  int flag=0;
#ifdef DEBUG
  printf("[%i] HMPI_Wait(%x, %x) type: %i\n", g_rank*g_nthreads+g_tl_tid, request, status, request->type);
  fflush(stdout);
#endif

  do {
    HMPI_Test(request, &flag, status);
  } while (flag!=1);

  return MPI_SUCCESS;
}


int HMPI_Isend(void* buf, int count, MPI_Datatype datatype, int dest, int tag, HMPI_Comm comm, HMPI_Request *req) {
  
#ifdef DEBUG
  printf("[%i] HMPI_Isend(%p, %i, %p, %i, %i, %p, %p) (proc null: %i)\n", g_rank*g_nthreads+g_tl_tid, buf, count, datatype, dest, tag, comm, req, MPI_PROC_NULL);
  fflush(stdout);
#endif


  if(unlikely(dest == MPI_PROC_NULL)) { 
    update_reqstat(req, 1);
    return MPI_SUCCESS;
  }

  req->status = MPI_STATUS_IGNORE;
#if 0
  int size;
  MPI_Type_size(datatype, &size);
#ifdef HMPI_SAFE
  MPI_Aint extent, lb;
  MPI_Type_get_extent(datatype, &lb, &extent);
  if(extent != size) {
    printf("non-contiguous derived datatypes are not supported yet!\n");
    MPI_Abort(comm->mpicomm, 0);
  }

  if(comm->mpicomm != MPI_COMM_WORLD) {
    printf("only MPI_COMM_WORLD is supported so far\n");
    MPI_Abort(comm->mpicomm, 0);
  }
#endif
#endif

  update_reqstat(req, 0);

  
  int target_mpi_rank = dest / g_nthreads;
  if(target_mpi_rank == g_rank) {
    int size;
    MPI_Type_size(datatype, &size);

    // send to other thread in my process
    req->type = HMPI_SEND;
    req->proc = g_nthreads*g_rank+g_tl_tid; // my local rank
    req->tag = tag;
    req->size = size*count;
    req->buf = buf;

    int target_mpi_thread = dest % g_nthreads;

    //printf("[%i] LOCAL sending to thread %i at rank %i\n", g_nthreads*g_rank+g_tl_tid, target_mpi_thread, target_mpi_rank);
    add_send_req(req, target_mpi_thread);
  } else {
    //int target_mpi_thread = dest % g_nthreads;
    //printf("[%i] MPI sending to thread %i at rank %i\n", g_nthreads*g_rank+g_tl_tid, target_mpi_thread, target_mpi_rank);
    req->type = MPI_SEND;
    MPI_Isend(buf, count, datatype, target_mpi_rank, tag, g_tcomms[g_tl_tid], &req->req);
  }

//  add_req(req);
  return MPI_SUCCESS;
}


int HMPI_Send(void* buf, int count, MPI_Datatype datatype, int dest, int tag, HMPI_Comm comm) {
  HMPI_Request req;
  HMPI_Isend(buf, count, datatype, dest, tag, comm, &req);
  HMPI_Wait(&req, MPI_STATUS_IGNORE);
  return MPI_SUCCESS;
}


int HMPI_Irecv(void* buf, int count, MPI_Datatype datatype, int source, int tag, HMPI_Comm comm, HMPI_Request *req) {

  //if(unlikely(source == MPI_ANY_SOURCE)) source = HMPI_ANY_SOURCE;
  //if(unlikely(tag == MPI_ANY_TAG)) tag = HMPI_ANY_TAG;

#ifdef DEBUG
  printf("[%i] HMPI_Irecv(%x, %i, %x, %i, %i, %x, %x) (proc null: %i)\n", g_rank*g_nthreads+g_tl_tid, buf, count, datatype, source, tag, comm, req, MPI_PROC_NULL);
  fflush(stdout);
#endif


  if(unlikely(source == MPI_PROC_NULL)) { 
    update_reqstat(req, 1);
    return MPI_SUCCESS;
  }

  req->status = MPI_STATUS_IGNORE;
//  int size;
//  MPI_Type_size(datatype, &size);

#if 0
#ifdef HMPI_SAFE
  MPI_Aint extent, lb;
  MPI_Type_get_extent(datatype, &lb, &extent);
  if(extent != size) {
    printf("non-contiguous derived datatypes are not supported yet!\n");
    MPI_Abort(comm->mpicomm, 0);
  }

  if(comm->mpicomm != MPI_COMM_WORLD) {
    printf("only MPI_COMM_WORLD is supported so far\n");
    MPI_Abort(comm->mpicomm, 0);
  }
#endif 
#endif

  update_reqstat(req, 0);
  
  int source_mpi_rank = source / g_nthreads;
  if(source_mpi_rank == g_rank) {
    int size;
    MPI_Type_size(datatype, &size);

    // recv from other thread in my process
    req->type = HMPI_RECV;
    req->proc = source;
    req->tag = tag;
    req->size = size*count;
    req->buf = buf;

    //int tests=0;
    //while(HMPI_Progress_request(req) != 1 && ++tests<10);

    add_recv_req(req);
  } else if(source != MPI_ANY_SOURCE) {
    int source_mpi_thread = source % g_nthreads;
    //printf("%d buf %p count %d src %d tag %d req %p\n", g_rank*g_nthreads+g_tl_tid, buf, count, source, tag, req);
    MPI_Irecv(buf, count, datatype, source_mpi_rank, tag, g_tcomms[source_mpi_thread], &req->req);

    req->type = MPI_RECV;
  } else if(source == MPI_ANY_SOURCE) {
    int size;
    MPI_Type_size(datatype, &size);

    // test both layers and pick first 
    req->type = HMPI_RECV_ANY_SOURCE;
    req->proc = source;
    req->tag = tag;
    req->size = size*count;
    req->buf = buf;

    req->comm = g_tcomms[g_tl_tid]; // not 100% sure -- this doesn't catch all messages -- Probe would need to loop over all thread comms and lock :-(
    req->datatype = datatype;

    add_recv_req(req);
  }

  return MPI_SUCCESS;
}

int HMPI_Recv(void* buf, int count, MPI_Datatype datatype, int source, int tag, HMPI_Comm comm, MPI_Status *status) {
  HMPI_Request req;
  HMPI_Irecv(buf, count, datatype, source, tag, comm, &req);
  HMPI_Wait(&req, status);
  return MPI_SUCCESS;
}

int HMPI_Barrier(HMPI_Comm comm) {
#ifdef DEBUG
  printf("in HMPI_Barrier\n"); fflush(stdout);
#endif

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  // all root-threads perform MPI_Barrier 
  if(g_tl_tid == 0) {
      //int rank;
      //MPI_Comm_rank(comm->mpicomm, &rank);
      MPI_Barrier(comm->mpicomm);
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);
  return MPI_SUCCESS;
}

// declaration
//extern "C" {
int NBC_Operation(void *buf3, void *buf1, void *buf2, MPI_Op op, MPI_Datatype type, int count);
//}

int HMPI_Allreduce(void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_Op op, HMPI_Comm comm) {

  MPI_Aint extent, lb;
  int size;
  int i;

  MPI_Type_size(datatype, &size);
  MPI_Type_get_extent(datatype, &lb, &extent);

  if(extent != size) {
    printf("allreduce non-contiguous derived datatypes are not supported yet!\n");
    fflush(stdout);
    MPI_Abort(comm->mpicomm, 0);
  }


#ifdef DEBUG
  printf("[%i %i] HMPI_Allreduce(%p, %p, %i, %p, %p, %p)\n", g_rank*g_nthreads+g_tl_tid, g_tl_tid, sendbuf, recvbuf,  count, datatype, op, comm);
  fflush(stdout);
#endif

  void* localbuf = NULL;

  if(g_tl_tid == 0) {
    localbuf = memalign(4096, size * count);
    memcpy(localbuf, sendbuf, size * count);
    //comm->rootsbuf = localbuf;
    //comm->rootrbuf = recvbuf;
    comm->sbuf[0] = localbuf;
    comm->rbuf[0] = recvbuf;
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  for(i=1; i<g_nthreads; ++i) {
     if(g_tl_tid == i) {
         NBC_Operation((void*)comm->sbuf[0], (void*)comm->sbuf[0], sendbuf, op, datatype, count);
     }

    barrier(&comm->barr);
    barrier_wait(&comm->barr);
  }

  if(g_tl_tid == 0) {
    MPI_Allreduce((void*)comm->sbuf[0], (void*)comm->rbuf[0], count, datatype, op, comm->mpicomm);
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  if(g_tl_tid != 0) memcpy(recvbuf, (void*)comm->rbuf[0], count*size);

  // protect from early leave (rootrbuf)
  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  if(g_tl_tid == 0) {
    free(localbuf);
  }

  return MPI_SUCCESS;
}


int HMPI_Bcast(void *buffer, int count, MPI_Datatype datatype, int root, HMPI_Comm comm) {
  MPI_Aint extent, lb;
  int size;

  MPI_Type_size(datatype, &size);
  MPI_Type_get_extent(datatype, &lb, &extent);

#ifdef HMPI_SAFE
  if(extent != size) {
    printf("bcast non-contiguous derived datatypes are not supported yet!\n");
    MPI_Abort(comm->mpicomm, 0);
  }
#endif
  
#ifdef DEBUG
  printf("[%i] HMPI_Bcast(%x, %i, %x, %i, %x)\n", g_rank*g_nthreads+g_tl_tid, buffer, count, datatype, root, comm);
#endif

  //We need a buffer set on all MPI ranks, so use thread root % tid
  //if(root == g_nthreads*g_rank+g_tl_tid) {
  if(root % g_nthreads == g_tl_tid) {
      comm->sbuf[0] = buffer;
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  if(g_tl_tid == 0) {
    MPI_Bcast((void*)comm->sbuf[0], count, datatype, root, comm->mpicomm);
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  if(root % g_nthreads != g_tl_tid) {
    memcpy(buffer, (void*)comm->sbuf[0], count*size);
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

#if 0
  //TODO AWF -- uhh this wont work when root != 0
  if(g_tl_tid == 0) {
    comm->sbuf[0]=buffer;
    MPI_Bcast(buffer, count, datatype, root, comm->mpicomm);
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  if(g_tl_tid != 0) memcpy(buffer, (void*)comm->sbuf[0], count*size);

  barrier(&comm->barr);
  barrier_wait(&comm->barr);
#endif
  return MPI_SUCCESS;
}


// TODO - scatter and gather may not work right for count > 1

int HMPI_Scatter(void* sendbuf, int sendcount, MPI_Datatype sendtype, void* recvbuf, int recvcount, MPI_Datatype recvtype, int root, HMPI_Comm comm) {
  MPI_Aint send_extent, recv_extent, lb;
  int send_size;
  int recv_size;
  int size;

  MPI_Type_size(sendtype, &send_size);
  MPI_Type_size(recvtype, &recv_size);
  MPI_Type_get_extent(sendtype, &lb, &send_extent);
  MPI_Type_get_extent(recvtype, &lb, &recv_extent);
  size = recv_size * recvcount;

  if(send_extent != send_size || recv_extent != recv_size) {
    printf("scatter non-contiguous derived datatypes are not supported yet!\n");
    MPI_Abort(comm->mpicomm, 0);
  }

  if(size != send_size * sendcount) {
    printf("different send and receive size is not supported!\n");
    MPI_Abort(comm->mpicomm, 0);
  }
 
#ifdef DEBUG
  printf("[%i] HMPI_Scatter(%p, %i, %p, %p, %i, %p, %i, %p)\n", g_rank*g_nthreads+g_tl_tid, sendbuf, sendcount, sendtype, recvbuf, recvcount, recvtype, root, comm);
#endif

  //On the proc with the root, pass the send buffer to thread 0
  if(g_rank * g_nthreads + g_tl_tid == root) {
      comm->sbuf[0] = sendbuf;
      comm->scount[0] = sendcount;
      comm->stype[0] = sendtype;
  }

  if(g_tl_tid == 0) {
    comm->rbuf[0] = memalign(4096, size * g_nthreads);

    if(root / g_nthreads != g_rank) {
        //root is not on this node, set the send type to something
        comm->sbuf[0] = NULL;
        comm->scount[0] = recvcount;
        comm->stype[0] = recvtype;
    }
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  //Just do a scatter!
  if(g_tl_tid == 0) {
    MPI_Scatter((void*)comm->sbuf[0], (int)comm->scount[0] * g_nthreads,
            (MPI_Datatype)comm->stype[0], (void*)comm->rbuf[0],
            recvcount * g_nthreads, recvtype, root / g_nthreads, comm->mpicomm);
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  //Each thread copies out of the root buffer
  if(recvbuf == MPI_IN_PLACE) {
      printf("in place scatter\n");
    memcpy(sendbuf, (void*)((uintptr_t)comm->rbuf[0] + size * g_tl_tid), size);
  } else {
    memcpy(recvbuf, (void*)((uintptr_t)comm->rbuf[0] + size * g_tl_tid), size);
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  if(g_tl_tid == 0) {
      free((void*)comm->rbuf[0]);
  }

  return MPI_SUCCESS;
}


// TODO - scatter and gather may not work right for count > 1

int HMPI_Gather(void* sendbuf, int sendcount, MPI_Datatype sendtype, void* recvbuf, int recvcount, MPI_Datatype recvtype, int root, HMPI_Comm comm)
{
  MPI_Aint send_extent, recv_extent, lb;
  int send_size;
  int recv_size;
  int size;

  MPI_Type_size(sendtype, &send_size);
  MPI_Type_size(recvtype, &recv_size);
  MPI_Type_get_extent(sendtype, &lb, &send_extent);
  MPI_Type_get_extent(recvtype, &lb, &recv_extent);
  size = send_size * sendcount;

  if(send_extent != send_size || recv_extent != recv_size) {
    printf("gather non-contiguous derived datatypes are not supported yet!\n");
    MPI_Abort(comm->mpicomm, 0);
  }

  if(size != recv_size * recvcount) {
    printf("different send and receive size is not supported!\n");
    MPI_Abort(comm->mpicomm, 0);
  }
 
#ifdef DEBUG
  printf("[%i] HMPI_Gather(%p, %i, %p, %p, %i, %p, %i, %p)\n", g_rank*g_nthreads+g_tl_tid, sendbuf, sendcount, sendtype, recvbuf, recvcount, recvtype, root, comm);
#endif

  //How do I want to do this?
  //Gather using the root threads, then pass the buffer pointer to the root
  //On the proc with the root, pass the send buffer to thread 0
  if(g_rank * g_nthreads + g_tl_tid == root) {
      comm->rbuf[0] = recvbuf;
      comm->rcount[0] = recvcount;
      comm->rtype[0] = recvtype;
  }

  if(g_tl_tid == 0) {
      comm->sbuf[0] = memalign(4096, size * g_nthreads);

    if(root / g_nthreads != g_rank) {
        //root is not on this node, set the recv type to something
        comm->rbuf[0] = NULL;
        comm->rcount[0] = sendcount;
        comm->rtype[0] = sendtype;
    }
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  //Each thread copies into the send buffer
  memcpy((void*)((uintptr_t)comm->sbuf[0] + size * g_tl_tid), sendbuf, size);

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  if(g_tl_tid == 0) {
    MPI_Gather((void*)comm->sbuf[0], sendcount * g_nthreads,
            sendtype, (void*)comm->rbuf[0],
            recvcount * g_nthreads, recvtype, root / g_nthreads, comm->mpicomm);
    free((void*)comm->sbuf[0]);
  }

  return MPI_SUCCESS;
}


#if 0
int HMPI_Alltoall(void* sendbuf, int sendcount, MPI_Datatype sendtype, void* recvbuf, int recvcount, MPI_Datatype recvtype, HMPI_Comm comm) 
{
  MPI_Aint send_extent, recv_extent, lb;
  void* rbuf;
  int32_t send_size;
  int32_t recv_size;
  uint64_t size;

  MPI_Type_size(sendtype, &send_size);
  MPI_Type_size(recvtype, &recv_size);
  MPI_Type_get_extent(sendtype, &lb, &send_extent);
  MPI_Type_get_extent(recvtype, &lb, &recv_extent);

  if(send_extent != send_size || recv_extent != recv_size) {
    printf("alltoall non-contiguous derived datatypes are not supported yet!\n");
    MPI_Abort(comm->mpicomm, 0);
  }

  if(send_size * sendcount != recv_size * recvcount) {
    printf("different send and receive size is not supported!\n");
    MPI_Abort(comm->mpicomm, 0);
  }

#ifdef DEBUG
  printf("[%i] HMPI_Alltoall(%p, %i, %p, %p, %i, %p, %p)\n", g_rank*g_nthreads+g_tl_tid, sendbuf, sendcount, sendtype, recvbuf, recvcount, recvtype, comm);
#endif

  uint64_t comm_size = g_nthreads * g_size;
  uint64_t data_size = send_size * sendcount;

  //Alloc a temp buffer
  if(g_tl_tid == 0) {
      comm->sbuf[0] = memalign(4096, data_size * g_nthreads * comm_size);
      comm->rbuf[0] = memalign(4096, data_size * g_nthreads * comm_size);
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  //Copy into the shared send buffer on a stride by g_nthreads
  //This way our temp buffer has all the data going to proc 0, then proc 1, etc
  uintptr_t offset = g_tl_tid * data_size;
  uintptr_t scale = data_size * g_nthreads;

  //Verified from (now missing) prints, this is correct
  for(uintptr_t i = 0; i < comm_size; i++) {
      memcpy((void*)((uintptr_t)(comm->sbuf[0]) + (scale * i) + offset),
              (void*)((uintptr_t)sendbuf + data_size * i), data_size);
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  //Do the MPI alltoall
  if(g_tl_tid == 0) {
      MPI_Datatype dt_send;
      MPI_Datatype dt_recv;

      //Seems like we should multiply by comm_size, but alltoall already
      // assumes one element per process.  We do have g_nthreads per process
      // though, so we multiply by that.
      MPI_Type_contiguous(sendcount * g_nthreads * g_nthreads, sendtype, &dt_send);
      MPI_Type_commit(&dt_send);

      MPI_Type_contiguous(recvcount * g_nthreads * g_nthreads, recvtype, &dt_recv);
      MPI_Type_commit(&dt_recv);

      MPI_Alltoall((void*)comm->sbuf[0], 1, dt_send,
              (void*)comm->rbuf[0], 1, dt_recv, comm->mpicomm);

      MPI_Type_free(&dt_send);
      MPI_Type_free(&dt_recv);
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  //Need to do g_size memcpy's -- one block of data per MPI process.
  // We copy g_nthreads * data_size at a time.
  offset = g_tl_tid * data_size * g_nthreads;
  scale = data_size * g_nthreads * g_nthreads;
  size = g_nthreads * data_size;

  for(uint64_t i = 0; i < g_size; i++) {
      memcpy((void*)((uintptr_t)recvbuf + size * i),
              (void*)((uintptr_t)comm->rbuf[0] + (scale * i) + offset),
              size);
  }

  barrier(&comm->barr);
  barrier_wait(&comm->barr);

  if(g_tl_tid == 0) {
      free((void*)comm->sbuf[0]);
      free((void*)comm->rbuf[0]);
  }
}
#endif

int HMPI_Alltoall(void* sendbuf, int sendcount, MPI_Datatype sendtype, void* recvbuf, int recvcount, MPI_Datatype recvtype, HMPI_Comm comm) 
{
  MPI_Aint send_extent, recv_extent, lb;
  //void* rbuf;
  int32_t send_size;
  int32_t recv_size;
  //uint64_t t1, t2, tmp;
  //HRT_TIMESTAMP_T t1, t2;
  //uint64_t tmp;

  PROFILE_START(g_profile_info[g_tl_tid], alltoall);

  MPI_Type_size(sendtype, &send_size);
  MPI_Type_size(recvtype, &recv_size);
  MPI_Type_get_extent(sendtype, &lb, &send_extent);
  MPI_Type_get_extent(recvtype, &lb, &recv_extent);

  if(send_extent != send_size || recv_extent != recv_size) {
    printf("alltoall non-contiguous derived datatypes are not supported yet!\n");
    MPI_Abort(comm->mpicomm, 0);
  }

  if(send_size * sendcount != recv_size * recvcount) {
    printf("different send and receive size is not supported!\n");
    MPI_Abort(comm->mpicomm, 0);
  }

#ifdef DEBUG
  printf("[%i] HMPI_Alltoall(%p, %i, %p, %p, %i, %p, %p)\n", g_rank*g_nthreads+g_tl_tid, sendbuf, sendcount, sendtype, recvbuf, recvcount, recvtype, comm);
#endif

  uint64_t data_size = send_size * sendcount;

  //Construct a vector type for the send side.
  // We use this to interleave the data from each local thread.

  MPI_Address(sendbuf, (MPI_Aint*)&comm->sbuf[g_tl_tid]);
  comm->scount[g_tl_tid] = sendcount;
  comm->stype[g_tl_tid] = sendtype;

  MPI_Address(recvbuf, (MPI_Aint*)&comm->rbuf[g_tl_tid]);
  comm->rcount[g_tl_tid] = recvcount * g_nthreads;
  comm->rtype[g_tl_tid] = recvtype;

  //PROFILE_START(g_profile_info[g_tl_tid], barrier);
  barrier(&comm->barr);
  barrier_wait(&comm->barr);
  //PROFILE_STOP(g_profile_info[g_tl_tid], barrier);

  //Do the MPI alltoall
  if(g_tl_tid == 0) {
      MPI_Datatype dt_send;
      MPI_Datatype dt_recv;
      MPI_Datatype dt_tmp;
      //MPI_Datatype dt_tmp2;
      MPI_Aint lb;
      MPI_Aint extent;

      //For the send side, we create an hindexed type to stride across each
      //thread's send buffer first, then build a contiguous type to group the
      //data for the different threads of each process.
      MPI_Type_create_hindexed(g_nthreads,
              (int*)comm->scount, (MPI_Aint*)comm->sbuf, sendtype, &dt_tmp);

      MPI_Type_get_extent(dt_tmp, &lb, &extent);
      MPI_Type_create_resized(dt_tmp, lb, data_size, &dt_send);
      //MPI_Type_contiguous(g_nthreads, dt_tmp2, &dt_send);

      MPI_Type_commit(&dt_send);
      MPI_Type_free(&dt_tmp);
      //MPI_Type_free(&dt_tmp2);

      //MPI_Type_commit(&dt_send);

      //For the receive side, we build a contiguous datatype (actually, just
      //the recvtype and recvcount * numthreads) representing all the data from
      //all threads on another process.  An hindexed type is used to split the
      //data across the receive buffers of each local thread.

      //We have g_nthreads receive buffers, one from each thread.
      //Each buffer holds recvcount * g_nthreads elements per process.
      MPI_Type_create_hindexed(g_nthreads,
              (int*)comm->rcount, (MPI_Aint*)comm->rbuf, recvtype, &dt_tmp);

      MPI_Type_get_extent(dt_tmp, &lb, &extent);
      MPI_Type_create_resized(dt_tmp, lb, data_size * g_nthreads, &dt_recv);

      MPI_Type_commit(&dt_recv);
      MPI_Type_free(&dt_tmp);

      MPI_Alltoall(MPI_BOTTOM, g_nthreads, dt_send,
              MPI_BOTTOM, 1, dt_recv, comm->mpicomm);

      MPI_Type_free(&dt_send);
      MPI_Type_free(&dt_recv);
  }

//  PROFILE_START(g_profile_info[g_tl_tid], barrier);
  barrier(&comm->barr);
  barrier_wait(&comm->barr);
//  PROFILE_STOP(g_profile_info[g_tl_tid], barrier);

  PROFILE_STOP(g_profile_info[g_tl_tid], alltoall);
  return MPI_SUCCESS;
}


int HMPI_Alltoall_local(void* sendbuf, int sendcount, MPI_Datatype sendtype, void* recvbuf, int recvcount, MPI_Datatype recvtype, HMPI_Comm comm) 
{
    MPI_Aint send_extent, recv_extent, lb;
    int32_t send_size;
    int32_t recv_size;
    int thr, i;

    PROFILE_START(alltoall);
    MPI_Type_size(sendtype, &send_size);
    MPI_Type_size(recvtype, &recv_size);

#if HMPI_SAFE
    MPI_Type_get_extent(sendtype, &lb, &send_extent);
    MPI_Type_get_extent(recvtype, &lb, &recv_extent);

    if(send_extent != send_size || recv_extent != recv_size) {
        printf("alltoall non-contiguous derived datatypes are not supported yet!\n");
        MPI_Abort(comm->mpicomm, 0);
    }

    if(send_size * sendcount != recv_size * recvcount) {
        printf("different send and receive size is not supported!\n");
        MPI_Abort(comm->mpicomm, 0);
    }
#endif

  comm->sbuf[g_tl_tid] = sendbuf;
  //comm->scount[g_tl_tid] = sendcount;
  //comm->stype[g_tl_tid] = sendtype;

  //comm->rbuf[g_tl_tid] = recvbuf;
  //comm->rcount[g_tl_tid] = recvcount;
  //comm->rtype[g_tl_tid] = recvtype;

  barrier(&comm->barr);

  //Do the self copy
  int copy_len = send_size * sendcount;
  memcpy((void*)((uintptr_t)recvbuf + (g_tl_tid * copy_len)),
         (void*)((uintptr_t)sendbuf + (g_tl_tid * copy_len)) , copy_len);

  barrier_wait(&comm->barr);

  //Push local data to each other thread's receive buffer.
  //For each thread, memcpy from my send buffer into their receive buffer.

  //TODO - try staggering
  for(thr = 1; thr < g_nthreads; thr++) {
      int t = (g_tl_tid + thr) % g_nthreads;
      memcpy((void*)((uintptr_t)recvbuf + (t * copy_len)),
             (void*)((uintptr_t)comm->sbuf[t] + (g_tl_tid * copy_len)) , copy_len);
      //memcpy((void*)((uintptr_t)comm->rbuf[thr] + (g_tl_tid * copy_len)),
      //       (void*)((uintptr_t)sendbuf + (thr * copy_len)) , copy_len);
  }

  PROFILE_START(barrier);
  barrier(&comm->barr);
  barrier_wait(&comm->barr);
  PROFILE_STOP(barrier);
  PROFILE_STOP(alltoall);
  return MPI_SUCCESS;
}


